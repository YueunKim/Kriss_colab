{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "3. AutoGrad.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YueunKim/Kriss_colab/blob/master/3_AutoGrad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU6VeXl7KOcx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dc906f5-1a7f-45bb-9ba6-7c1204522ea5"
      },
      "source": [
        "#3, p.13\n",
        "import torch\n",
        "x = torch.tensor([1., 2.])\n",
        "y = torch.tensor([4., 5.])\n",
        "z = torch.tensor([7., 3.])\n",
        "x.requires_grad"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MBe09FNKOc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce0da92a-9753-457f-8c19-26c166b1bfec"
      },
      "source": [
        "(x + y).requires_grad"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Aj74qzVKOc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c41a20d0-7e72-44e5-fdb0-316cb1c85949"
      },
      "source": [
        "z.requires_grad = True\n",
        "(x + z).requires_grad"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qczrXGCmSjE4",
        "outputId": "ce34d76d-62a1-48bd-b580-0c7c7389ed01"
      },
      "source": [
        "import torch\r\n",
        "a, b = torch.rand((2,2)), torch.rand((2,2))\r\n",
        "print(\"a: {}\\n, b: {} \\n\".format(a, b))\r\n",
        "\r\n",
        "var1 = torch.sum(torch.abs((a * b)), 1)\r\n",
        "print(\"L1 Distance is : \", var1)\r\n",
        "\r\n",
        "var2 = torch.norm(((a * b)), 1, -1)\r\n",
        "print(\"Torch NORM L1 Distance is : \", var2)\r\n",
        "\r\n",
        "var3 = torch.sum(((a * b)) ** 2, 1).sqrt()\r\n",
        "print(\"L2 SDistance is : \", var3)\r\n",
        "\r\n",
        "var4 = torch.norm(((a * b)), 2, -1)\r\n",
        "print(\"Torch NORM L2 Distance is : \", var4)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a: tensor([[0.9096, 0.9174],\n",
            "        [0.3563, 0.3930]])\n",
            ", b: tensor([[0.2491, 0.4702],\n",
            "        [0.6783, 0.6028]]) \n",
            "\n",
            "L1 Distance is :  tensor([0.6580, 0.4786])\n",
            "Torch NORM L1 Distance is :  tensor([0.6580, 0.4786])\n",
            "L2 SDistance is :  tensor([0.4872, 0.3384])\n",
            "Torch NORM L2 Distance is :  tensor([0.4872, 0.3384])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmUqWHalYlz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f306a25b-b466-43ea-8163-0854c50db87e"
      },
      "source": [
        "#3, p.16\r\n",
        "x = torch.tensor([-3., 2., 5.]).requires_grad_()\r\n",
        "u = x.pow(3).sum()\r\n",
        "print(\"x.grad:{}\\n u.backward:{}\\n x.grad:{}\\n\".format(x.grad, u.backward(), x.grad))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x.grad:None\n",
            " u.backward:None\n",
            " x.grad:tensor([27., 12., 75.])\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJh8hhujKOc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b22def85-a8e9-4717-813b-7acfbdca103e"
      },
      "source": [
        "#3, p.21\n",
        "w1 = torch.rand(20, 10).requires_grad_()\n",
        "b1 = torch.rand(20).requires_grad_()\n",
        "w2 = torch.rand(5, 20).requires_grad_()\n",
        "b2 = torch.rand(5).requires_grad_()\n",
        "print('w1:{} \\n, b1:{} \\n, w2:{} \\n, b2:{} \\n'.format(w1, b1, w2, b2))\n",
        "\n",
        "x = torch.rand(10)\n",
        "h = torch.tanh(w1 @ x + b1)\n",
        "y = torch.tanh(w2 @ h + b2)\n",
        "print('x:{} \\n, h:{} \\n, y:{} \\n'.format(x, h, y))\n",
        "\n",
        "target = torch.rand(5)\n",
        "loss = (y - target).pow(2).mean()\n",
        "print('target: {}\\n, loss: {}\\n'.format( target, loss))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w1:tensor([[0.2438, 0.2192, 0.2099, 0.4254, 0.4836, 0.4383, 0.5023, 0.0505, 0.4520,\n",
            "         0.5421],\n",
            "        [0.1613, 0.6693, 0.0581, 0.9759, 0.2089, 0.2755, 0.7721, 0.3915, 0.6880,\n",
            "         0.7741],\n",
            "        [0.6675, 0.2729, 0.6611, 0.2859, 0.7660, 0.5485, 0.6604, 0.0780, 0.3108,\n",
            "         0.5777],\n",
            "        [0.6078, 0.2387, 0.8852, 0.8101, 0.8601, 0.7025, 0.7041, 0.0924, 0.9289,\n",
            "         0.4318],\n",
            "        [0.6175, 0.2457, 0.0445, 0.5730, 0.3299, 0.1900, 0.1962, 0.0935, 0.1735,\n",
            "         0.7486],\n",
            "        [0.1867, 0.7411, 0.6782, 0.6259, 0.7114, 0.1523, 0.6799, 0.2032, 0.7471,\n",
            "         0.2332],\n",
            "        [0.5244, 0.1238, 0.4171, 0.6089, 0.3961, 0.6099, 0.0103, 0.4071, 0.2423,\n",
            "         0.6791],\n",
            "        [0.5749, 0.1897, 0.9231, 0.8840, 0.2795, 0.6557, 0.2769, 0.0350, 0.6572,\n",
            "         0.1030],\n",
            "        [0.8459, 0.4087, 0.0504, 0.3173, 0.8814, 0.9572, 0.0065, 0.0771, 0.3666,\n",
            "         0.6724],\n",
            "        [0.8572, 0.0736, 0.8769, 0.2313, 0.6769, 0.9435, 0.4397, 0.8888, 0.7743,\n",
            "         0.9753],\n",
            "        [0.7954, 0.3335, 0.1357, 0.6792, 0.8523, 0.6022, 0.3000, 0.0315, 0.1650,\n",
            "         0.5478],\n",
            "        [0.6508, 0.5038, 0.8221, 0.3222, 0.2233, 0.5533, 0.9877, 0.6738, 0.7273,\n",
            "         0.0569],\n",
            "        [0.6113, 0.9637, 0.1993, 0.4449, 0.6632, 0.8576, 0.0393, 0.2868, 0.5805,\n",
            "         0.4924],\n",
            "        [0.3352, 0.4951, 0.0104, 0.8042, 0.5247, 0.3323, 0.4404, 0.9319, 0.5222,\n",
            "         0.1859],\n",
            "        [0.4556, 0.0644, 0.6412, 0.7387, 0.6590, 0.8477, 0.3369, 0.4719, 0.6918,\n",
            "         0.2590],\n",
            "        [0.3648, 0.2058, 0.2853, 0.8167, 0.1534, 0.1208, 0.4397, 0.1035, 0.6002,\n",
            "         0.5446],\n",
            "        [0.0583, 0.0673, 0.7493, 0.5456, 0.7803, 0.8733, 0.6750, 0.5542, 0.5003,\n",
            "         0.7615],\n",
            "        [0.3552, 0.4656, 0.9207, 0.1349, 0.2680, 0.9647, 0.9130, 0.5079, 0.8520,\n",
            "         0.8472],\n",
            "        [0.7669, 0.7567, 0.8025, 0.3578, 0.4243, 0.6098, 0.9131, 0.0711, 0.1719,\n",
            "         0.5656],\n",
            "        [0.3647, 0.0675, 0.1726, 0.2703, 0.9204, 0.1287, 0.6485, 0.3902, 0.6142,\n",
            "         0.5819]], requires_grad=True) \n",
            ", b1:tensor([0.3220, 0.4021, 0.4000, 0.1291, 0.5373, 0.0680, 0.8017, 0.3345, 0.1778,\n",
            "        0.4487, 0.7883, 0.3996, 0.1515, 0.4285, 0.0661, 0.4592, 0.9770, 0.9659,\n",
            "        0.5408, 0.8857], requires_grad=True) \n",
            ", w2:tensor([[0.1629, 0.9335, 0.6468, 0.6624, 0.8678, 0.7235, 0.1197, 0.9400, 0.3582,\n",
            "         0.1626, 0.7282, 0.7047, 0.3723, 0.6023, 0.4046, 0.3547, 0.5012, 0.0514,\n",
            "         0.8912, 0.3657],\n",
            "        [0.3674, 0.5194, 0.3563, 0.8912, 0.6012, 0.4317, 0.2329, 0.1797, 0.6053,\n",
            "         0.4290, 0.0180, 0.6325, 0.5444, 0.0111, 0.2071, 0.3054, 0.7080, 0.2030,\n",
            "         0.0231, 0.5536],\n",
            "        [0.3290, 0.9515, 0.7702, 0.2528, 0.5953, 0.4449, 0.0883, 0.8218, 0.9011,\n",
            "         0.9812, 0.2831, 0.6945, 0.5422, 0.6923, 0.2583, 0.9242, 0.7764, 0.9974,\n",
            "         0.7145, 0.5720],\n",
            "        [0.2118, 0.1188, 0.1883, 0.7877, 0.2703, 0.8267, 0.6581, 0.0124, 0.8581,\n",
            "         0.0946, 0.2376, 0.7257, 0.9801, 0.8601, 0.4086, 0.3433, 0.3107, 0.3258,\n",
            "         0.6706, 0.9936],\n",
            "        [0.8020, 0.5406, 0.0372, 0.2115, 0.3412, 0.8617, 0.2649, 0.2655, 0.1810,\n",
            "         0.8040, 0.5499, 0.1684, 0.0887, 0.4412, 0.9892, 0.9347, 0.5321, 0.0180,\n",
            "         0.1872, 0.8902]], requires_grad=True) \n",
            ", b2:tensor([0.9489, 0.2707, 0.4384, 0.5738, 0.0343], requires_grad=True) \n",
            "\n",
            "x:tensor([0.7258, 0.1299, 0.3141, 0.8351, 0.0481, 0.4332, 0.8424, 0.2976, 0.5715,\n",
            "        0.2773]) \n",
            ", h:tensor([0.9646, 0.9945, 0.9881, 0.9965, 0.9709, 0.9785, 0.9885, 0.9919, 0.9645,\n",
            "        0.9975, 0.9930, 0.9965, 0.9729, 0.9885, 0.9870, 0.9860, 0.9976, 0.9989,\n",
            "        0.9958, 0.9913], grad_fn=<TanhBackward>) \n",
            ", y:tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<TanhBackward>) \n",
            "\n",
            "target: tensor([0.6509, 0.2495, 0.9367, 0.8665, 0.9673])\n",
            ", loss: 0.14159855246543884\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxubKv47KOc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d520b58-5c71-4069-e1ce-930a9092cd93"
      },
      "source": [
        "#3, p.22\n",
        "w = torch.rand(3, 10, 10).requires_grad_()\n",
        "\n",
        "def blah(k, x):\n",
        "    for i in range(k):\n",
        "        x = torch.tanh(w[i] @ x)\n",
        "    return x\n",
        "\n",
        "u = blah(1, torch.rand(10))\n",
        "v = blah(3, torch.rand(10))\n",
        "q = u.dot(v)\n",
        "print('w: {} \\n, u: {}\\n, v: {}\\n q: {}\\n'.format(w, u, v, q))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w: tensor([[[0.4016, 0.5643, 0.8041, 0.0343, 0.9006, 0.6548, 0.7330, 0.3341,\n",
            "          0.0540, 0.0440],\n",
            "         [0.6942, 0.0375, 0.4551, 0.3140, 0.6910, 0.8053, 0.6692, 0.7501,\n",
            "          0.4711, 0.2952],\n",
            "         [0.5780, 0.1283, 0.3007, 0.1687, 0.0269, 0.9150, 0.5099, 0.0366,\n",
            "          0.6634, 0.4998],\n",
            "         [0.2787, 0.4167, 0.7726, 0.7636, 0.8691, 0.6200, 0.2659, 0.0664,\n",
            "          0.7403, 0.5818],\n",
            "         [0.2650, 0.4073, 0.4706, 0.7319, 0.8563, 0.5405, 0.2593, 0.0215,\n",
            "          0.3746, 0.4530],\n",
            "         [0.2640, 0.2602, 0.3294, 0.1234, 0.5493, 0.6062, 0.3205, 0.1389,\n",
            "          0.5221, 0.3786],\n",
            "         [0.4305, 0.7185, 0.9859, 0.8080, 0.9135, 0.6430, 0.0735, 0.5485,\n",
            "          0.2739, 0.8506],\n",
            "         [0.5572, 0.5658, 0.0013, 0.4289, 0.3149, 0.8674, 0.7013, 0.6257,\n",
            "          0.9080, 0.7448],\n",
            "         [0.7563, 0.3855, 0.7714, 0.7064, 0.2360, 0.1531, 0.9290, 0.5205,\n",
            "          0.5772, 0.8378],\n",
            "         [0.7318, 0.1809, 0.0613, 0.7885, 0.2985, 0.7038, 0.6526, 0.2346,\n",
            "          0.7493, 0.8822]],\n",
            "\n",
            "        [[0.7975, 0.7908, 0.2591, 0.6272, 0.3180, 0.6980, 0.0194, 0.3514,\n",
            "          0.6510, 0.0915],\n",
            "         [0.0457, 0.4206, 0.9500, 0.6139, 0.3612, 0.3837, 0.7768, 0.8956,\n",
            "          0.6073, 0.0924],\n",
            "         [0.2905, 0.5838, 0.1991, 0.2215, 0.4489, 0.8233, 0.2074, 0.2039,\n",
            "          0.3858, 0.6153],\n",
            "         [0.7243, 0.5350, 0.0021, 0.0605, 0.5920, 0.8324, 0.0719, 0.0125,\n",
            "          0.6986, 0.1186],\n",
            "         [0.1537, 0.9636, 0.5364, 0.6810, 0.2603, 0.6404, 0.7837, 0.6903,\n",
            "          0.5629, 0.9440],\n",
            "         [0.1309, 0.7502, 0.6195, 0.9375, 0.7890, 0.0428, 0.4975, 0.1564,\n",
            "          0.0126, 0.1817],\n",
            "         [0.0421, 0.0571, 0.1845, 0.5101, 0.5518, 0.7689, 0.4881, 0.4733,\n",
            "          0.0348, 0.3208],\n",
            "         [0.7092, 0.1358, 0.5802, 0.2942, 0.1474, 0.8560, 0.3312, 0.8478,\n",
            "          0.1273, 0.6861],\n",
            "         [0.6147, 0.4270, 0.1693, 0.0122, 0.0627, 0.8103, 0.0380, 0.0873,\n",
            "          0.8913, 0.8607],\n",
            "         [0.0488, 0.8892, 0.5509, 0.9290, 0.0323, 0.8868, 0.8404, 0.1961,\n",
            "          0.9443, 0.3000]],\n",
            "\n",
            "        [[0.1518, 0.4533, 0.0270, 0.2394, 0.2305, 0.1672, 0.4449, 0.1365,\n",
            "          0.1206, 0.1836],\n",
            "         [0.2558, 0.4903, 0.2523, 0.8743, 0.5779, 0.4922, 0.6611, 0.7542,\n",
            "          0.9143, 0.7751],\n",
            "         [0.2861, 0.2668, 0.0103, 0.8639, 0.2048, 0.7158, 0.3517, 0.9188,\n",
            "          0.2061, 0.4305],\n",
            "         [0.8145, 0.6267, 0.1583, 0.3432, 0.0968, 0.7763, 0.5414, 0.0791,\n",
            "          0.8541, 0.7461],\n",
            "         [0.7470, 0.9117, 0.9439, 0.2900, 0.6715, 0.1887, 0.8579, 0.8050,\n",
            "          0.3941, 0.7408],\n",
            "         [0.4068, 0.7031, 0.3892, 0.3516, 0.9575, 0.9590, 0.7756, 0.4275,\n",
            "          0.8466, 0.5997],\n",
            "         [0.8708, 0.4391, 0.0629, 0.3191, 0.8040, 0.2606, 0.0614, 0.5439,\n",
            "          0.7084, 0.4602],\n",
            "         [0.3229, 0.9677, 0.3792, 0.8676, 0.5005, 0.1406, 0.5510, 0.4877,\n",
            "          0.7717, 0.1482],\n",
            "         [0.5196, 0.4659, 0.4849, 0.8738, 0.4089, 0.1009, 0.9125, 0.5791,\n",
            "          0.0637, 0.8133],\n",
            "         [0.1603, 0.1172, 0.7955, 0.4903, 0.2751, 0.9285, 0.8750, 0.5369,\n",
            "          0.6823, 0.0389]]], requires_grad=True) \n",
            ", u: tensor([0.8591, 0.9477, 0.8251, 0.8464, 0.7996, 0.6914, 0.9149, 0.9547, 0.9610,\n",
            "        0.9446], grad_fn=<TanhBackward>)\n",
            ", v: tensor([0.9734, 1.0000, 0.9996, 0.9999, 1.0000, 1.0000, 0.9998, 0.9999, 0.9999,\n",
            "        0.9999], grad_fn=<TanhBackward>)\n",
            " q: 8.720708847045898\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6HkMCdRYCxl",
        "outputId": "427ac0dd-2404-4c85-a694-13aeaf634aca"
      },
      "source": [
        "a = torch.tensor([1, 3])\r\n",
        "b = torch.tensor([2, 2])\r\n",
        "c = a.dot(b)\r\n",
        "c"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yENdMXNCYpzK",
        "outputId": "32e0412d-67ea-4147-b06d-08a937b42273"
      },
      "source": [
        "t = torch.tensor([1., 2., 4.]).requires_grad_()\r\n",
        "u = torch.tensor([10., 20.]).requires_grad_()\r\n",
        "a = t.pow(2).sum() + u.log().sum()\r\n",
        "r = torch.autograd.grad(a, (t, u))\r\n",
        "print(\"t:{} \\n u:{} \\n a:{} \\n r = {} \\n\".format(t, u, a, r))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t:tensor([1., 2., 4.], requires_grad=True) \n",
            " u:tensor([10., 20.], requires_grad=True) \n",
            " a:26.298316955566406 \n",
            " r = (tensor([2., 4., 8.]), tensor([0.1000, 0.0500])) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-_BHON4bJBc",
        "outputId": "a2d5ef36-f232-4484-fd9a-3d1354676d08"
      },
      "source": [
        "s = u.log().sum()\r\n",
        "torch.autograd.grad(s, u)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.1000, 0.0500]),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30YmNAQYKOc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c61e7892-8485-48ba-e44c-dd3e2719eade"
      },
      "source": [
        "w = torch.rand(3, 10).requires_grad_()\n",
        "x = torch.rand(10)\n",
        "y = w @ x\n",
        "print('w: {},\\n x: {},\\n y: {}'.format(w, x, y))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w: tensor([[0.9088, 0.0129, 0.2507, 0.8754, 0.3919, 0.7446, 0.4900, 0.6081, 0.1300,\n",
            "         0.6680],\n",
            "        [0.5865, 0.0103, 0.7796, 0.4534, 0.2015, 0.1284, 0.2013, 0.6560, 0.4843,\n",
            "         0.6856],\n",
            "        [0.6809, 0.3889, 0.9415, 0.9398, 0.2798, 0.5233, 0.7171, 0.2097, 0.7541,\n",
            "         0.0031]], requires_grad=True),\n",
            " x: tensor([0.3153, 0.0828, 0.0921, 0.3796, 0.8560, 0.9496, 0.1313, 0.7212, 0.9424,\n",
            "        0.1953]),\n",
            " y: tensor([2.4414, 1.8140, 2.3834], grad_fn=<MvBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jusJSKSDfMyB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efe93ebb-a100-464f-8cf4-659d46d220bf"
      },
      "source": [
        "w1 = torch.rand(5, 5).requires_grad_()\r\n",
        "w2 = torch.rand(5, 5).requires_grad_()\r\n",
        "x = torch.empty(5).normal_()\r\n",
        "print(\"w1:{} \\n w2: {} \\n x : {}\\n\".format(w1, w2, x))\r\n",
        "\r\n",
        "x0 = x\r\n",
        "x1 = w1 @ x0\r\n",
        "x2 = x0 + w2 @ x1\r\n",
        "x3 = w1 @ (x1 + x2)\r\n",
        "\r\n",
        "q = x3.norm()\r\n",
        "\r\n",
        "q.backward()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w1:tensor([[0.5169, 0.1589, 0.6770, 0.3035, 0.1148],\n",
            "        [0.0027, 0.4072, 0.3252, 0.8551, 0.0736],\n",
            "        [0.8257, 0.3258, 0.8955, 0.1060, 0.8489],\n",
            "        [0.8150, 0.8017, 0.9622, 0.7748, 0.8278],\n",
            "        [0.9394, 0.8869, 0.3062, 0.2317, 0.0723]], requires_grad=True) \n",
            " w2: tensor([[0.3676, 0.6446, 0.0566, 0.9806, 0.0760],\n",
            "        [0.4358, 0.9686, 0.4406, 0.8527, 0.8919],\n",
            "        [0.0031, 0.8759, 0.7321, 0.4866, 0.0521],\n",
            "        [0.6613, 0.2223, 0.1640, 0.0271, 0.4499],\n",
            "        [0.3262, 0.4558, 0.0912, 0.8121, 0.2938]], requires_grad=True) \n",
            " x : tensor([-0.3104, -1.9273,  1.0491,  0.0967, -0.2798])\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNt3AnRKfiSt",
        "outputId": "61e8ee23-46d5-45e1-f38b-b400dfdced0e"
      },
      "source": [
        "x = torch.tensor([1.0, -2.0, 3.0, -4.0]).requires_grad_()\r\n",
        "a = x.abs()\r\n",
        "s = a.sum()\r\n",
        "s\r\n",
        "\r\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10., grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srMSzsbofnT2",
        "outputId": "cb8a7121-e1a4-474b-9508-19f03e43e6b1"
      },
      "source": [
        "s.grad_fn.next_functions"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((<AbsBackward at 0x7f94cb49fa90>, 0),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMy6tHh5fzO2",
        "outputId": "b92ec4d9-9e62-40ca-c79b-7342a6998127"
      },
      "source": [
        "x = torch.tensor([1., 2., 2.]).requires_grad_()\r\n",
        "q = x.norm()\r\n",
        "q"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3., grad_fn=<CopyBackwards>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JWXyWn6KOc2"
      },
      "source": [
        "#3, p.24\n",
        "x = torch.rand(784)\n",
        "w = torch.empty(10, 784).normal_(0, 1e-3).requires_grad_()\n",
        "b = torch.empty(10).normal_(0, 1e-3).requires_grad_()\n",
        "y = torch.rand(10)\n",
        "eta = 0.01\n",
        "\n",
        "for k in range(10001):\n",
        "    y_hat = x @ w.t() + b\n",
        "    loss = (y_hat - y).pow(2).mean()\n",
        "\n",
        "    w.grad, b.grad = None, None\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        w -= eta * w.grad\n",
        "        b -= eta * b.grad"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNFzcJDkKOc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e2fe8a2-ffd8-4dcf-fd91-c8e6e47ea0b0"
      },
      "source": [
        "#3, p.26\n",
        "a = torch.tensor( 0.5).requires_grad_()\n",
        "b = torch.tensor(-0.5).requires_grad_()\n",
        "for k in range(100):\n",
        "    l = (a - 1)**2 + (b + 1)**2 + (a - b)**2\n",
        "    ga, gb = torch.autograd.grad(l, (a, b))\n",
        "    with torch.no_grad():\n",
        "        a -= eta * ga\n",
        "        b -= eta * gb\n",
        "print('%.06f' % a.item(), '%.06f' % b.item())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.333676 -0.333676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIPFzlwFKOc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f922e59-a6d1-41f6-e8fe-8d01cb7b8098"
      },
      "source": [
        "#3, p.27\n",
        "a = torch.tensor( 0.5).requires_grad_()\n",
        "b = torch.tensor(-0.5).requires_grad_()\n",
        "for k in range(100):\n",
        "    l = (a - 1)**2 + (b + 1)**2 + (a.detach() - b)**2\n",
        "    ga, gb = torch.autograd.grad(l, (a, b))\n",
        "    with torch.no_grad():\n",
        "        a -= eta * ga\n",
        "        b -= eta * gb\n",
        "print('%.06f' % a.item(), '%.06f' % b.item())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.933690 -0.066310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylaTGzqkKOc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf05ded4-6107-4b6b-ca04-18e42adeb205"
      },
      "source": [
        "#3, p.28\n",
        "x = torch.tensor([1., 2., 3.]).requires_grad_()\n",
        "phi = x.pow(2).sum()\n",
        "g1, = torch.autograd.grad(phi, x, create_graph = True)\n",
        "g1"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 4., 6.], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc9Lpz0CKOc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "453ef10d-a061-400e-83eb-b28f9649c1c9"
      },
      "source": [
        "#3, p.28\n",
        "psi = g1[0].exp() - g1[2].exp()\n",
        "g2, = torch.autograd.grad(psi, x)\n",
        "g2"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  14.7781,    0.0000, -806.8576])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JYKIRfnKOc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "outputId": "9fcfb58b-c87a-498a-aea7-37a52c116f38"
      },
      "source": [
        "#3, p.29\n",
        "x = torch.tensor([1., 2., 3.]).requires_grad_()\n",
        "y = x.sin()\n",
        "print('y : {}'.format(y))\n",
        "l = y.sum()\n",
        "l.backward()\n",
        "print('l=sum(x.sin()), l : {}'.format(l))\n",
        "y = x.sin()\n",
        "y += 1\n",
        "print('y : {}'.format(y))\n",
        "l = y.sum()\n",
        "l.backward()\n",
        "print('l=sum(x.sin()+1), l : {}'.format(l))\n",
        "y = x.sin()\n",
        "y *=y\n",
        "print('y : {}'.format(y))\n",
        "l = y.sum()\n",
        "print('l=sum(x.sin()*x.sin()), l : {}'.format(l))\n",
        "l.backward()\n",
        "print('l : {}'.format(l))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y : tensor([0.8415, 0.9093, 0.1411], grad_fn=<SinBackward>)\n",
            "l=sum(x.sin()), l : 1.8918883800506592\n",
            "y : tensor([1.8415, 1.9093, 1.1411], grad_fn=<AddBackward0>)\n",
            "l=sum(x.sin()+1), l : 4.891888618469238\n",
            "y : tensor([0.7081, 0.8268, 0.0199], grad_fn=<MulBackward0>)\n",
            "l=sum(x.sin()*x.sin()), l : 1.5548100471496582\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-6e432f0ea7bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'l=sum(x.sin()*x.sin()), l : {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'l : {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [3]], which is output 0 of SinBackward, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OezP_83KOc2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}